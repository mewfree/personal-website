<!doctype html><html lang="en"><head><title>Machine Learning - Damien Gonot</title><link rel="stylesheet" href="/main.css"><link rel="stylesheet" href="/katex.min.css"><link rel="canonical" href="https://www.damiengonot.com/notes/computer-science/artificial-intelligence/machine-learning"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="Homepage  Notes  Computer Science  Artificial Intelligence  Machine
Learning

Artificial Neural Networks

Deep Learning

Large Language Models

 Next word prediction

Resources

Intro to Large Language Models  Andrej Karpathy

httpswwwyoutubecomwatchvzjkBMFhNj_g

Happy New Year GPT in 500 lines o..."><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body class="bg-white dark:bg-black"><header class="bg-indigo-600 dark:bg-black text-center text-white p-8"><div class="dg text-4xl font-bold mb-4">Damien Gonot</div><div class="text-xl flex flex-wrap gap-x-4 gap-y-2 justify-center"><a href="/" class="hover:underline">Home</a> <a href="/blog" class="hover:underline">Blog</a> <a href="/notes" class="hover:underline">Notes</a> <a href="/about" class="hover:underline">About</a> <button id="theme" class="text-2xl hover:cursor-pointer hover:dark" onclick="toggleTheme()">üåù</button></div><script src="/custom.js"></script><script src="/highlight.js"></script><script defer="defer" src="/katex.min.js"></script><script defer="defer" src="/katex-auto-render.min.js"></script></header><div class="prose prose-indigo dark:prose-invert dark:prose-a:text-indigo-400 max-w-3xl mx-auto p-8"><h1>Machine Learning</h1><p><a href="../../../homepage">Homepage</a> / <a href="../../../notes">Notes</a> / <a href="../../computer-science">Computer Science</a> / <a href="../artificial-intelligence">Artificial Intelligence</a> / Machine Learning</p><h2 id="artificial-neural-networks">Artificial Neural Networks</h2><h3 id="deep-learning">Deep Learning</h3><h4 id="large-language-models">Large Language Models</h4><ul><li>Next word prediction</li></ul><h5 id="resources">Resources</h5><h6 id="intro-to-large-language-models---andrej-karpathy">Intro to Large Language Models - Andrej Karpathy</h6><p><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">https://www.youtube.com/watch?v=zjkBMFhNj_g</a></p><h6 id="happy-new-year-gpt-in-500-lines-of-sql">Happy New Year: GPT in 500 lines of SQL</h6><p><a href="https://explainextended.com/2023/12/31/happy-new-year-15/">https://explainextended.com/2023/12/31/happy-new-year-15/</a></p><h4 id="quantization">Quantization</h4><p>Process of reducing the number of bits (weights and biases) of a model/neural network. The primary goal is to compress the model in size for faster execution/computation without sacrificing too much in terms of accuracy.</p><p>Example: FP32 ("full precision"), FP16 ("half precision")</p><p>The more bits we use to represent a value, the more precise it generally is. The more bits we have available, the larger the range of values that can be represented.</p><h5 id="resources-1">Resources</h5><h6 id="a-visual-guide-to-quantization">A Visual Guide to Quantization</h6><p><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization">https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization</a></p><h4 id="lora-low-rank-adaptation">LoRA (Low-Rank Adaptation)</h4><p>Efficient training method by creating and updating low-rank approximations of the original weight matrices (update matrices).</p><h4 id="resources-2">Resources</h4><h5 id="mit-6.s191-introduction-to-deep-learning">MIT 6.S191: Introduction to Deep Learning</h5><p><a href="http://introtodeeplearning.com/">http://introtodeeplearning.com/</a></p><h5 id="nyu-ds-ga-1008-deep-learning">NYU DS-GA 1008: Deep Learning</h5><p><a href="https://atcold.github.io/pytorch-Deep-Learning/">https://atcold.github.io/pytorch-Deep-Learning/</a></p><h5 id="uc-berkeley-full-stack-deep-learning">UC Berkeley Full Stack Deep Learning</h5><ul><li><a href="https://fullstackdeeplearning.com/">https://fullstackdeeplearning.com/</a></li><li><a href="https://inst.eecs.berkeley.edu/~cs194/">https://inst.eecs.berkeley.edu/~cs194/</a></li></ul><h5 id="uc-berkeley-cs182-designing-visualizing-and-understanding-deep-neural-networks">UC Berkeley CS182: Designing, Visualizing and Understanding Deep Neural Networks</h5><p><a href="https://www2.eecs.berkeley.edu/Courses/CS182/">https://www2.eecs.berkeley.edu/Courses/CS182/</a></p><h5 id="deep-learning-book-by-mit-press">Deep Learning Book by MIT Press</h5><p><a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></p><h5 id="cornell-cs5787-deep-learning">Cornell CS5787: Deep Learning</h5><h5 id="introduction-to-deep-learning">Introduction to Deep Learning</h5><p><a href="https://sebastianraschka.com/blog/2021/dl-course.html">https://sebastianraschka.com/blog/2021/dl-course.html</a></p><h5 id="physics-based-deep-learning-book">Physics-based Deep Learning Book</h5><p><a href="https://physicsbaseddeeplearning.org/intro.html">https://physicsbaseddeeplearning.org/intro.html</a></p><h5 id="deep-learning-with-python">Deep Learning with Python</h5><p>by Fran√ßois Chollet</p><h5 id="practical-deep-learning">Practical Deep Learning</h5><blockquote><p>A free course designed for people with some coding experience, who want to learn how to apply deep learning and machine learning to practical problems.</p></blockquote><p><a href="https://course.fast.ai/">https://course.fast.ai/</a></p><h5 id="building-llms-from-the-ground-up-a-3-hour-coding-workshop">Building LLMs from the Ground Up: A 3-hour Coding Workshop</h5><p><a href="https://www.youtube.com/watch?v=quh7z1q7-uc">https://www.youtube.com/watch?v=quh7z1q7-uc</a></p><h3 id="gradient-descent">Gradient descent</h3><p>A method of mathematical optimization. Algorithm to find the local minimum of a loss function.</p><h3 id="resources-3">Resources</h3><h4 id="neural-networks-zero-to-hero">Neural Networks: Zero to Hero</h4><blockquote><p>A course by Andrej Karpathy on building neural networks, from scratch, in code. We start with the basics of backpropagation and build up to modern deep neural networks, like GPT. In my opinion language models are an excellent place to learn deep learning, even if your intention is to eventually go to other areas like computer vision because most of what you learn will be immediately transferable. This is why we dive into and focus on languade models. Prerequisites: solid programming (Python), intro-level math (e.g. derivative, gaussian).</p></blockquote><p><a href="https://karpathy.ai/zero-to-hero.html">https://karpathy.ai/zero-to-hero.html</a></p><h2 id="tools">Tools</h2><h3 id="weights-biases-wb">Weights &amp; Biases (W&amp;B)</h3><p><a href="https://wandb.ai/site">https://wandb.ai/site</a></p><blockquote><p>The AI Developer Platform Weights &amp; Biases helps AI developers build better models faster. Quickly track experiments, version and iterate on datasets, evaluate model performance, reproduce models, and manage your ML workflows end-to-end.</p></blockquote><h2 id="resources-4">Resources</h2><h3 id="cornell-cs5785-applied-machine-learning">Cornell CS5785: Applied Machine Learning</h3><p><a href="https://cornelltech.github.io/cs5785-fall-2018/index.html">https://cornelltech.github.io/cs5785-fall-2018/index.html</a></p><h3 id="hands-on-machine-learning-with-scikit-learn-and-tensorflow">Hands-On Machine Learning with Scikit-Learn and Tensorflow</h3><p>by Aur√©lien G√©ron</p><h3 id="machine-learning-engineering-open-book">Machine Learning Engineering Open Book</h3><p><a href="https://github.com/stas00/ml-engineering">https://github.com/stas00/ml-engineering</a></p></div></body></html>